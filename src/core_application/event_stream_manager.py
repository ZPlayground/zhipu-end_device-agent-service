"""
Redis Streams äº‹ä»¶æµç®¡ç†å™¨
Redis Streams Event Stream Manager

è´Ÿè´£ï¼š
1. ä½¿ç”¨Redis Streamsç®¡ç†è®¾å¤‡æ•°æ®æµ
2. éŸ³è§†é¢‘å›¾ç‰‡ç­‰å¤§æ–‡ä»¶å•ç‹¬å­˜å‚¨åœ¨æ–‡ä»¶ç³»ç»Ÿ
3. ä¸ºLLM Agentæä¾›æ•°æ®è¯»å–æ¥å£
4. è‡ªåŠ¨æ¸…ç†è¿‡æœŸæ•°æ®
"""
import asyncio
import logging
import uuid
import os
import json
import hashlib
from typing import Dict, List, Optional, Any
from datetime import datetime, timedelta
from pathlib import Path

from src.data_persistence.terminal_device_models import DataType
from config.settings import settings
from config.redis_config import redis_config

logger = logging.getLogger(__name__)

try:
    import redis.asyncio as redis
except ImportError:
    import redis
    redis.Redis = redis.StrictRedis


class RedisStreamsManager:
    """Redis Streams äº‹ä»¶æµç®¡ç†å™¨"""
    
    def __init__(self):
        # ä½¿ç”¨Redisé…ç½®
        self.redis_host = redis_config.host
        self.redis_port = redis_config.port
        self.redis_db = redis_config.db
        self.redis_password = redis_config.password
        
        self.redis: Optional[redis.Redis] = None
        self._connected = False
        
        # æ–‡ä»¶å­˜å‚¨é…ç½®
        self.file_storage_dir = Path(redis_config.file_storage_dir)
        self.file_storage_dir.mkdir(parents=True, exist_ok=True)
        
        # å­˜å‚¨ç­–ç•¥é…ç½®
        self.max_redis_size = redis_config.max_redis_size_bytes
        
        # æµç®¡ç†
        self.stream_prefix = redis_config.stream_prefix
        self.consumer_group = redis_config.consumer_group
        self.consumer_name = f"agent_{uuid.uuid4().hex[:8]}"
        
        # æ¸…ç†é…ç½®
        self.data_retention_hours = redis_config.data_retention_hours
        self.cleanup_interval_minutes = redis_config.cleanup_interval_minutes
        
        self._cleanup_task = None
        self._running = False
        
        logger.info("âœ… Redis Streams ç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆ")
    
    async def initialize(self):
        """åˆå§‹åŒ–Redisè¿æ¥"""
        try:
            self.redis = redis.Redis(
                host=self.redis_host,
                port=self.redis_port,
                db=self.redis_db,
                password=self.redis_password,
                decode_responses=False  # ä¿æŒäºŒè¿›åˆ¶æ•°æ®
            )
            
            # æµ‹è¯•è¿æ¥
            await self.redis.ping()
            self._connected = True
            
            # å¯åŠ¨æ¸…ç†ä»»åŠ¡
            await self.start_cleanup_task()
            
            logger.info(f"âœ… Redis Streams è¿æ¥æˆåŠŸ: {self.redis_host}:{self.redis_port}")
            
        except Exception as e:
            logger.error(f"âŒ Redis è¿æ¥å¤±è´¥: {e}")
            self._connected = False
            raise
    
    async def close(self):
        """å…³é—­è¿æ¥"""
        self._running = False
        if self._cleanup_task:
            self._cleanup_task.cancel()
        
        if self.redis:
            await self.redis.close()
            self._connected = False
        
        logger.info("ğŸ”´ Redis Streams ç®¡ç†å™¨å·²å…³é—­")
    
    def start_maintenance(self):
        """å¯åŠ¨ç»´æŠ¤ä»»åŠ¡ï¼ˆåŒæ­¥æ–¹æ³•ï¼Œç”¨äºå…¼å®¹ç°æœ‰ä»£ç ï¼‰"""
        try:
            logger.info("ğŸ”§ å¯åŠ¨Redis Streamsç»´æŠ¤ä»»åŠ¡...")
            # å¼‚æ­¥å¯åŠ¨æ¸…ç†ä»»åŠ¡
            asyncio.create_task(self._start_maintenance_async())
            logger.info("âœ… Redis Streamsç»´æŠ¤ä»»åŠ¡å·²å¯åŠ¨")
        except Exception as e:
            logger.error(f"âŒ å¯åŠ¨ç»´æŠ¤ä»»åŠ¡å¤±è´¥: {e}")
    
    async def _start_maintenance_async(self):
        """å¼‚æ­¥å¯åŠ¨ç»´æŠ¤ä»»åŠ¡"""
        try:
            # ç¡®ä¿Redisè¿æ¥å·²å»ºç«‹
            if not self._connected:
                await self.initialize()
            
            # å¯åŠ¨æ¸…ç†ä»»åŠ¡
            await self.start_cleanup_task()
            
        except Exception as e:
            logger.error(f"âŒ å¼‚æ­¥å¯åŠ¨ç»´æŠ¤ä»»åŠ¡å¤±è´¥: {e}")
    
    def _get_stream_key(self, device_id: str) -> str:
        """è·å–è®¾å¤‡æµé”®å"""
        return f"{self.stream_prefix}{device_id}"
    
    async def add_data_to_stream(
        self,
        device_id: str,
        data_type: DataType,
        content_text: Optional[str] = None,
        content_binary: Optional[bytes] = None,
        content_json: Optional[Dict[str, Any]] = None,
        metadata: Dict[str, Any] = None,
        mime_type: Optional[str] = None
    ) -> bool:
        """æ·»åŠ æ•°æ®åˆ°Redis Stream"""
        if not self._connected:
            logger.error("âŒ Redis æœªè¿æ¥ï¼Œæ— æ³•æ·»åŠ æ•°æ®")
            return False
        
        try:
            stream_key = self._get_stream_key(device_id)
            entry_id = str(uuid.uuid4())
            
            # æ„å»ºåŸºç¡€æ•°æ®
            stream_data = {
                "entry_id": entry_id,
                "device_id": device_id,
                "data_type": data_type.value,
                "created_at": datetime.utcnow().isoformat(),
                "metadata": json.dumps(metadata or {})
            }
            
            # å¤„ç†ä¸åŒç±»å‹çš„å†…å®¹
            if content_text:
                stream_data["content_text"] = content_text
                
            elif content_json:
                stream_data["content_json"] = json.dumps(content_json)
                
            elif content_binary:
                # å¤§æ–‡ä»¶æ£€æŸ¥
                if len(content_binary) > self.max_redis_size:
                    # å­˜å‚¨åˆ°æ–‡ä»¶ç³»ç»Ÿ
                    file_info = await self._store_large_file(
                        device_id, entry_id, content_binary, data_type, mime_type
                    )
                    stream_data.update(file_info)
                else:
                    # å°æ–‡ä»¶ç›´æ¥å­˜å‚¨åˆ°Redis
                    stream_data["content_binary"] = content_binary
                    if mime_type:
                        stream_data["mime_type"] = mime_type
            
            # æ·»åŠ åˆ°æµ
            message_id = await self.redis.xadd(stream_key, stream_data)
            
            # ç¡®ä¿æ¶ˆè´¹è€…ç»„å­˜åœ¨
            await self._ensure_consumer_group(stream_key)
            
            logger.debug(f"ğŸ“ æ·»åŠ æ•°æ®åˆ°Redis Stream: {device_id}, ID: {message_id}")
            return True
            
        except Exception as e:
            logger.error(f"âŒ æ·»åŠ æ•°æ®åˆ°Redis Streamå¤±è´¥: {e}")
            return False
    
    async def _store_large_file(
        self,
        device_id: str,
        entry_id: str,
        content: bytes,
        data_type: DataType,
        mime_type: Optional[str]
    ) -> Dict[str, str]:
        """å­˜å‚¨å¤§æ–‡ä»¶åˆ°æ–‡ä»¶ç³»ç»Ÿï¼Œè¿”å›æ–‡ä»¶ä¿¡æ¯"""
        try:
            # ç”Ÿæˆæ–‡ä»¶è·¯å¾„
            file_hash = hashlib.md5(content).hexdigest()
            device_dir = self.file_storage_dir / device_id
            device_dir.mkdir(exist_ok=True)
            
            # ç¡®å®šæ–‡ä»¶æ‰©å±•å
            ext = self._get_file_extension(mime_type, data_type)
            file_path = device_dir / f"{entry_id}_{file_hash}{ext}"
            
            # ä¿å­˜åŸæ–‡ä»¶
            with open(file_path, "wb") as f:
                f.write(content)
            
            file_info = {
                "file_path": str(file_path),
                "file_size": len(content),
                "file_hash": file_hash
            }
            
            if mime_type:
                file_info["mime_type"] = mime_type
            
            logger.info(f"ğŸ’¾ å¤§æ–‡ä»¶å­˜å‚¨: {device_id}, {len(content)}B -> {file_path}")
            return file_info
            
        except Exception as e:
            logger.error(f"âŒ å­˜å‚¨å¤§æ–‡ä»¶å¤±è´¥: {e}")
            return {"error": str(e)}
    
    def _get_file_extension(self, mime_type: Optional[str], data_type: DataType) -> str:
        """æ ¹æ®MIMEç±»å‹å’Œæ•°æ®ç±»å‹ç¡®å®šæ–‡ä»¶æ‰©å±•å"""
        if mime_type:
            ext_map = {
                "image/jpeg": ".jpg",
                "image/png": ".png",
                "image/gif": ".gif",
                "image/webp": ".webp",
                "audio/mpeg": ".mp3",
                "audio/wav": ".wav",
                "audio/ogg": ".ogg",
                "video/mp4": ".mp4",
                "video/webm": ".webm",
                "video/avi": ".avi"
            }
            return ext_map.get(mime_type, ".bin")
        
        # æ ¹æ®æ•°æ®ç±»å‹æ¨æ–­
        type_ext_map = {
            DataType.IMAGE: ".jpg",
            DataType.AUDIO: ".wav",
            DataType.VIDEO: ".mp4"
        }
        return type_ext_map.get(data_type, ".bin")
    
    async def _ensure_consumer_group(self, stream_key: str):
        """ç¡®ä¿æ¶ˆè´¹è€…ç»„å­˜åœ¨"""
        try:
            await self.redis.xgroup_create(
                stream_key, self.consumer_group, id="0", mkstream=True
            )
        except redis.ResponseError as e:
            if "BUSYGROUP" not in str(e):
                logger.error(f"âŒ åˆ›å»ºæ¶ˆè´¹è€…ç»„å¤±è´¥: {e}")
    
    async def read_stream_data(
        self,
        device_id: str,
        count: int = 10,
        block_ms: int = 1000
    ) -> List[Dict[str, Any]]:
        """ä»Redis Streamè¯»å–æ•°æ®"""
        if not self._connected:
            return []
        
        try:
            stream_key = self._get_stream_key(device_id)
            
            # ç¡®ä¿æ¶ˆè´¹è€…ç»„å­˜åœ¨
            await self._ensure_consumer_group(stream_key)
            
            # è¯»å–æ•°æ®
            messages = await self.redis.xreadgroup(
                self.consumer_group,
                self.consumer_name,
                {stream_key: ">"},
                count=count,
                block=block_ms
            )
            
            result = []
            for stream, msgs in messages:
                for msg_id, fields in msgs:
                    # è§£ææ¶ˆæ¯
                    data = await self._parse_stream_message(fields)
                    data["message_id"] = msg_id.decode()
                    result.append(data)
                    
                    # ç¡®è®¤æ¶ˆæ¯å¤„ç†
                    await self.redis.xack(stream_key, self.consumer_group, msg_id)
            
            return result
            
        except Exception as e:
            logger.error(f"âŒ è¯»å–Streamæ•°æ®å¤±è´¥: {e}")
            return []
    
    async def _parse_stream_message(self, fields: Dict) -> Dict[str, Any]:
        """è§£æStreamæ¶ˆæ¯"""
        try:
            data = {}
            
            # åŸºç¡€å­—æ®µ
            for key, value in fields.items():
                key_str = key.decode() if isinstance(key, bytes) else key
                
                if key_str in ["entry_id", "device_id", "created_at", "mime_type", "file_path"]:
                    data[key_str] = value.decode() if isinstance(value, bytes) else value
                elif key_str == "data_type":
                    data[key_str] = DataType(value.decode() if isinstance(value, bytes) else value)
                elif key_str in ["metadata", "content_json"]:
                    json_str = value.decode() if isinstance(value, bytes) else value
                    data[key_str] = json.loads(json_str)
                elif key_str == "content_text":
                    data[key_str] = value.decode() if isinstance(value, bytes) else value
                elif key_str == "content_binary":
                    data[key_str] = value  # ä¿æŒbytesæ ¼å¼
                elif key_str in ["file_size"]:
                    data[key_str] = int(value.decode() if isinstance(value, bytes) else value)
                else:
                    data[key_str] = value.decode() if isinstance(value, bytes) else value
            
            # å¦‚æœæœ‰æ–‡ä»¶è·¯å¾„ï¼Œè¯»å–æ–‡ä»¶å†…å®¹
            if "file_path" in data:
                try:
                    with open(data["file_path"], "rb") as f:
                        data["file_content"] = f.read()
                except Exception as e:
                    logger.error(f"âŒ è¯»å–æ–‡ä»¶å†…å®¹å¤±è´¥: {e}")
                    data["file_error"] = str(e)
            
            return data
            
        except Exception as e:
            logger.error(f"âŒ è§£ææ¶ˆæ¯å¤±è´¥: {e}")
            return {"error": str(e)}
    
    async def get_stream_info(self, device_id: str) -> Dict[str, Any]:
        """è·å–æµä¿¡æ¯"""
        if not self._connected:
            return {}
        
        try:
            stream_key = self._get_stream_key(device_id)
            info = await self.redis.xinfo_stream(stream_key)
            
            return {
                "stream_key": stream_key,
                "length": info[b"length"],
                "radix_tree_keys": info[b"radix-tree-keys"],
                "radix_tree_nodes": info[b"radix-tree-nodes"],
                "groups": info[b"groups"],
                "last_generated_id": info[b"last-generated-id"].decode(),
                "first_entry": info[b"first-entry"],
                "last_entry": info[b"last-entry"]
            }
            
        except Exception as e:
            logger.error(f"âŒ è·å–æµä¿¡æ¯å¤±è´¥: {e}")
            return {"error": str(e)}
    
    async def start_cleanup_task(self):
        """å¯åŠ¨æ¸…ç†ä»»åŠ¡"""
        if not self._running:
            self._running = True
            self._cleanup_task = asyncio.create_task(self._cleanup_loop())
            logger.info("âœ… å¯åŠ¨Redisæ•°æ®æ¸…ç†ä»»åŠ¡")
    
    async def _cleanup_loop(self):
        """æ¸…ç†å¾ªç¯"""
        while self._running:
            try:
                await self._cleanup_expired_data()
                await asyncio.sleep(self.cleanup_interval_minutes * 60)
            except asyncio.CancelledError:
                break
            except Exception as e:
                logger.error(f"âŒ æ¸…ç†ä»»åŠ¡å¼‚å¸¸: {e}")
                await asyncio.sleep(60)
    
    async def _cleanup_expired_data(self):
        """æ¸…ç†è¿‡æœŸæ•°æ®"""
        try:
            # è·å–æ‰€æœ‰è®¾å¤‡æµ
            pattern = f"{self.stream_prefix}*"
            stream_keys = await self.redis.keys(pattern)
            
            cleanup_count = 0
            file_cleanup_count = 0
            
            cutoff_time = datetime.utcnow() - timedelta(hours=self.data_retention_hours)
            cutoff_timestamp = int(cutoff_time.timestamp() * 1000)
            
            for stream_key in stream_keys:
                try:
                    # è·å–è¿‡æœŸæ¶ˆæ¯
                    messages = await self.redis.xrange(
                        stream_key, min="-", max=cutoff_timestamp
                    )
                    
                    for msg_id, fields in messages:
                        # åˆ é™¤å…³è”çš„æ–‡ä»¶
                        if b"file_path" in fields:
                            file_path = Path(fields[b"file_path"].decode())
                            if file_path.exists():
                                file_path.unlink()
                                file_cleanup_count += 1
                        
                        # ä»æµä¸­åˆ é™¤æ¶ˆæ¯
                        await self.redis.xdel(stream_key, msg_id)
                        cleanup_count += 1
                        
                except Exception as e:
                    logger.error(f"âŒ æ¸…ç†æµå¤±è´¥ {stream_key}: {e}")
            
            if cleanup_count > 0:
                logger.info(f"ğŸ§¹ æ¸…ç†å®Œæˆ: {cleanup_count} æ¡æ¶ˆæ¯, {file_cleanup_count} ä¸ªæ–‡ä»¶")
                
        except Exception as e:
            logger.error(f"âŒ æ¸…ç†è¿‡æœŸæ•°æ®å¤±è´¥: {e}")


# å…¨å±€å®ä¾‹
event_stream_manager = RedisStreamsManager()
